import requests
from bs4 import BeautifulSoup
from dataclasses import dataclass, field
from typing import List
import concurrent.futures
import re
import time
!pip install PyPDF2
import PyPDF2
import io

BUSQUEDAS = ["[O|o]ferta", "ciudad"] # Uso de expresiones regulares para las búsquedas
PROFUNDIDAD = 2 # Número de páginas que se comprobarán
TIEMPO_ESPERA = 1 # segundos de espera entre las consultas para cada documento encontrado

class COLOR_TERMINAL:
    MORADO = '\033[95m'
    AZUL_OSCURO = '\033[94m'
    AZUL_CLARO = '\033[96m'
    VERDE = '\033[92m'
    AMARILLO = '\033[93m'
    ROJO = '\033[91m'
    FIN = '\033[0m'
    NEGRITA = '\033[1m'
    SUBRAYADO = '\033[4m'

@dataclass 
class Coincidencias:
  busqueda: str
  coincidencias: int

@dataclass 
class Documento:
  url: str
  coincidencias: List[Coincidencias] = field(default_factory=list) 

@dataclass
class Expediente:
  nombre: str
  url: str
  documentos: List[Documento] = field(default_factory=list) 

@dataclass
class Pagina:
  indice: int
  url: str
  expediente: List[Expediente] = field(default_factory=list) 

@dataclass
class AnalisisExpediente:
  indice: int
  error: str
  documentos: List[Documento] = field(default_factory=list)
  
@dataclass
class Scraper:
  busquedas: List[str]
  profundidad: int
  sesion: requests.Session
  paginas: List[Pagina] = field(default_factory=list) 
  errores: List[str] = field(default_factory=list) 
  

  def buscar_expedientes(self):
    endpoint = "https://contrataciondelestado.es/wps/portal/licRecientes"
    datos_form = {}

    for i in range(self.profundidad):
      peticion = self.sesion.post(endpoint, data=datos_form)
      if peticion.status_code != 200:
        mensaje_error = f"ERROR: la petición correspondiente a la página {i} con la URL {endpoint} ha devuelto un status code no válido {peticion.status_code}"
        self.errores.append(mensaje_error)
        break

      soup = BeautifulSoup(peticion.text, "html.parser")
      referencias_expedientes = soup.select(".tdidExpedienteWidth a")
      if len(referencias_expedientes) != 6:
        mensaje_advertencia = f"ADVERTENCIA: en la página {i} con la URL {endpoint} se han encontrado {len(referencias_expedientes)} expedientes cuando se esperan 6"
        self.errores.append(mensaje_advertencia)
  
      expedientes: List[Expediente] = [] 
      for referencia_expediente in referencias_expedientes:
        nombre = referencia_expediente.text
        atributos_referencia = referencia_expediente.attrs
        url = f'https://contrataciondelestado.es{atributos_referencia["href"]}'
        expediente = Expediente(nombre, url, [])
        expedientes.append(expediente)

      pagina = Pagina(i, endpoint, expedientes)
      self.paginas.append(pagina)

      # Preparar siguiente página
      form = soup.select_one("form")
      if form == None:
        mensaje_error = f"ERROR: en la petición correspondiente a la página {i} con la URL {endpoint} no se ha encontrado el formulario que permite seguir paginando"
        self.errores.append(mensaje_error)
        break

      atributos_form = form.attrs
      form_name = atributos_form["name"]
      endpoint = f'https://contrataciondelestado.es{form["action"]}'      
      input_siguiente = form.select_one("input[id*=':liciRecientes:siguienteLink']")
      if input_siguiente == None:
        mensaje_error = f"ERROR: en la petición correspondiente a la página {i} con la URL {endpoint} no se ha encontrado el input que permite la petición a la siguiente página"
        self.errores.append(mensaje_error)
        break

      atributos_input = input_siguiente.attrs
      input_siguiente_name = atributos_input["name"]
      input_siguiente_value = atributos_input["value"]

      javax = form.select_one("input[name='javax.faces.ViewState']")
      if javax == None:
        mensaje_error = f"ERROR: en la petición correspondiente a la página {i} con la URL {endpoint} no se ha encontrado el input javax necesario para la petición a la siguiente página"
        self.errores.append(mensaje_error)
        break

      atributos_javax = javax.attrs
      javax_value = atributos_javax["value"]
      javax_name = atributos_javax["name"]

      datos_form = {
          form_name: form_name,
          input_siguiente_name: input_siguiente_value,
          javax_name: javax_value
      }

  def buscar_documentacion(self):
    for pagina in self.paginas:
      with concurrent.futures.ThreadPoolExecutor(max_workers=6) as manejador:
        promesas = []
        for indice, expediente in enumerate(pagina.expediente):
          promesas.append(manejador.submit(analizar_expediente, indice, expediente.url, self.sesion))
      for promesa in concurrent.futures.as_completed(promesas):
        resultado: AnalisisExpediente = promesa.result()
        if resultado.error != "":
          mensaje_error = f"ERROR: buscando los documentos del expediente {pagina.expediente[resultado.indice].nombre} ({pagina.expediente[resultado.indice].url} se ha obtenido el siguiente error: {resultado.error})"
          self.errores.append(mensaje_error)
          continue
        for documento in resultado.documentos:
          pagina.expediente[resultado.indice].documentos.append(documento)

  def analizar_documentacion(self):
    for pagina in self.paginas:
      for expediente in pagina.expediente:
        for documento in expediente.documentos:
          es_pdf = False
          respuesta = ""
          time.sleep(TIEMPO_ESPERA)
          peticion = self.sesion.get(documento.url)
          if peticion.status_code != 200:
            mensaje_error = f"ERROR: el documento {documento.url} correspondiente al expediente {expediente.nombre} ({expediente.url}) ha devuelto un status code incorrecto {pet.status_code}"
            self.errores.append(mensaje_error)
            continue
          tipo = peticion.headers["Content-Type"]
          if "pdf" in tipo:
            es_pdf = True
            respuesta = peticion.content
          if "/html" in tipo:
            soup = BeautifulSoup(peticion.text, "html.parser")
            respuesta = peticion.text
            redireccion = soup.select_one("meta[http-equiv='refresh']")
            if redireccion != None:
              redireccion_atributos = redireccion.attrs
              content = redireccion_atributos["content"]
              content = re.sub(r".*?'(.*?)'.*", r"\1", content)
              url_real_documento = f'https://contrataciondelestado.es{content}'
              pet = self.sesion.get(url_real_documento)
              if pet.status_code != 200:
                mensaje_error = f"ERROR: el documento {documento.url} correspondiente al expediente {expediente.nombre} ({expediente.url}) ha devuelto un status code incorrecto {pet.status_code}"
                self.errores.append(mensaje_error)
                continue
              tipo = pet.headers["Content-Type"]
              if "pdf" in tipo:
                respuesta = pet.content
                es_pdf = True
              if "html" in tipo:
                respuesta = pet.text

          if es_pdf:
            recopilacion_coincidencias = buscar_en_pdf(self.busquedas, respuesta)
          if es_pdf == False:
            recopilacion_coincidencias = buscar_coincidencias_texto_plano(self.busquedas, respuesta)

          for coincidencia in recopilacion_coincidencias:
            documento.coincidencias.append(coincidencia)

  def informar_resultados_detalle(self):
    informe_resultados = f"{COLOR_TERMINAL.AZUL_OSCURO}INFORME RESULTADOS:\n"
    for pagina in self.paginas:
      informe_resultados += f"Página {pagina.indice} ({pagina.url}):\n"
      informe_resultados += f"Se han encontrado {len(pagina.expediente)} expedientes.\n"
      for indice_expediente, expediente in enumerate(pagina.expediente):
        informe_resultados += f"   {indice_expediente + 1}. En el expediente {expediente.nombre} ({expediente.url}) se han encontrado {len(expediente.documentos)} documentos.\n"
        for indice_documento, documento in enumerate(expediente.documentos):
          informe_resultados += f"      {indice_expediente + 1}.{indice_documento + 1}. Resultado del análisis del documento {documento.url}:\n"
          for indice_coincidencia, coincidencia in enumerate(documento.coincidencias):
            informe_resultados += f"         {indice_expediente + 1}.{indice_documento + 1}.{indice_coincidencia + 1}. La búsqueda {coincidencia.busqueda} ha devuelto un total de {coincidencia.coincidencias} coincidencias.\n"
    informe_resultados += f"{COLOR_TERMINAL.FIN}"
    print(informe_resultados)

  def informar_resultados_resumen(self):
    informe_resultados = f"{COLOR_TERMINAL.VERDE}INFORME ANÁLISIS:\n"
    sin_coincidencias = True
    for pagina in self.paginas:
      for expediente in pagina.expediente:
        for documento in expediente.documentos:
          for coincidencia in documento.coincidencias:
            if coincidencia.coincidencias > 0:
              sin_coincidencias = False
              informe_resultados += f"Expediente {expediente.nombre}: {coincidencia.coincidencias} coincidencias para {coincidencia.busqueda} {expediente.url}\n"
    if sin_coincidencias:
      informe_resultados += "No se han encontrado coincidencias de búsqueda."
    informe_resultados += f"{COLOR_TERMINAL.FIN}"
    print(informe_resultados)

          
  def informar_errores(self):
    informe_errores = f"{COLOR_TERMINAL.ROJO}============================\n¡¡ATENCIÓN: SE HAN PRODUCIDO ERRORES DURANTE LA EJECUCIÓN!!"
    if len(self.errores) > 0:
      for error in self.errores:
        informe_errores += error + "\n"
      informe_errores += f"============================{COLOR_TERMINAL.FIN}"
      print(informe_errores)


def buscar_en_pdf(busquedas: List[str], respuesta):
  archivo = io.BytesIO(respuesta)
  lector = PyPDF2.PdfReader(archivo)
  contenido = ""
  for indice_pagina in range(len(lector.pages)):
    contenido += lector.pages[indice_pagina].extract_text()
  return buscar_coincidencias_texto_plano(busquedas, contenido)
  
def buscar_coincidencias_texto_plano(busquedas: List[str], respuesta:str):
  respuesta_minificada = re.sub("\n", "", respuesta)

  recopilacionCoincidencias:List[Coincidencias] = []
  for busqueda in busquedas:
    coincidencias = re.findall(busqueda, respuesta_minificada)
    coincidencia = Coincidencias(busqueda, len(coincidencias))
    recopilacionCoincidencias.append(coincidencia)

  return recopilacionCoincidencias


def analizar_expediente(indice: int, url: str, sesion: requests.Session):
  analisExpediente = AnalisisExpediente(indice, "")
  peticion = sesion.get(url)
  if peticion.status_code != 200:
    analisExpediente.error = f"status code incorrecto {peticion.status_code}"
    return analisExpediente

  soup = BeautifulSoup(peticion.text, "html.parser")
  tablas_resultados = soup.select(".dataTableEx")
  if tablas_resultados == None:
    return analisExpediente

  documentos:List[Documento] = []
  for tabla in tablas_resultados:
    enlaces = tabla.select("a")
    for enlace in enlaces:
      if "Sello de Tiempo" in enlace.text:
        continue
      atributos_enlace = enlace.attrs
      href = atributos_enlace["href"]
      if href.startswith("http") == False:
        href = f'https://contrataciondelestado.es{href}'
      documento = Documento(href, [])
      documentos.append(documento)

  analisExpediente.documentos = documentos
  return analisExpediente

  
def ejecutar():
  sesion = requests.session()
  scraper = Scraper(BUSQUEDAS, PROFUNDIDAD, sesion=sesion)
  scraper.buscar_expedientes()
  scraper.buscar_documentacion()
  scraper.analizar_documentacion()
  scraper.informar_resultados_detalle()
  scraper.informar_resultados_resumen()
  scraper.informar_errores() 
  
if __name__ == "__main__":
  ejecutar()
